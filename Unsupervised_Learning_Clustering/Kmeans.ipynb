{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# K Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import cluster, datasets, mixture\n",
    "\n",
    "np.random.seed(844)\n",
    "clust1 = np.random.normal(5, 2, (1000,2))\n",
    "clust2 = np.random.normal(15, 3, (1000,2))\n",
    "clust3 = np.random.multivariate_normal([17,3], [[1,0],[0,1]], 1000)\n",
    "clust4 = np.random.multivariate_normal([2,16], [[1,0],[0,1]], 1000)\n",
    "dataset1 = np.concatenate((clust1, clust2, clust3, clust4))\n",
    "\n",
    "# we take the first array as the second array has the cluster labels\n",
    "dataset2 = datasets.make_circles(n_samples=1000, factor=.5, noise=.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot clustering output on the two datasets\n",
    "def plot_two_cluster(df1, df2, color1, color2, title1,  title2):\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(6*2, 3*2)\n",
    "    ax1.set_title(title1,fontsize=14)\n",
    "    ax1.set_xlim(min(df1[:,0]), max(df1[:,0]))\n",
    "    ax1.set_ylim(min(df1[:,1]), max(df1[:,1]))\n",
    "    ax1.scatter(df1[:, 0], df1[:, 1],s=8,lw=0,c= color1)\n",
    "    \n",
    "    ax2.set_title(title2,fontsize=14)\n",
    "    ax2.set_xlim(min(df2[:,0]), max(df2[:,0]))\n",
    "    ax2.set_ylim(min(df2[:,1]), max(df2[:,1]))\n",
    "    ax2.scatter(df2[:, 0], df2[:, 1],s=8,lw=0,c=color2)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # plot clustering output on the two datasets\n",
    "def plot_one_cluster(df1, color1, title1):\n",
    "    fig, (ax) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(6*2, 3*2)\n",
    "    ax.set_title(title1,fontsize=14)\n",
    "    ax.set_xlim(min(df1[:,0]), max(df1[:,0]))\n",
    "    ax.set_ylim(min(df1[:,1]), max(df1[:,1]))\n",
    "    ax.scatter(df1[:, 0], df1[:, 1],s=8,lw=0,c= color1)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_two_cluster(df1=dataset1, df2=dataset2, color1 = 'gray', color2 = 'gray', title1 = 'Dataset 1',  title2 = 'Dataset 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "K-means in scikit provides some benefits over the traditional approach. \n",
    "\n",
    "* n_init :The former just reruns the algorithm with n different initialisations and returns the best output (measured by the within cluster sum of squares). \n",
    "* init='kmeans++' : The initial centres are smartly selected (i.e. better than random). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying k-means\n",
    "kmeans_dataset1 = cluster.KMeans(n_clusters=4, max_iter=300, init='k-means++',n_init=10).fit_predict(dataset1)\n",
    "kmeans_dataset2 = cluster.KMeans(n_clusters=2, max_iter=300, init='k-means++',n_init=10).fit_predict(dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_two_cluster(df1=dataset1, df2=dataset2, color1 = kmeans_dataset1,\n",
    "              color2 = kmeans_dataset2, title1 = 'Dataset 1',  title2 = 'Dataset 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-means performs quite well on ``Dataset1``, but fails miserably on ``Dataset2``. In fact, these two datasets illustrate the strenghts and weaknesses of k-means. The algorithm seeks and identifies globular (essentially spherical) clusters. If this assumption doesn't hold, the model output may be inadaquate (or just really bad). It doesn't end there; k-means can also underperform with clusters of different size and density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_dataset1 = cluster.KMeans(n_clusters=4, max_iter=300, \n",
    "                                 init='k-means++',n_init=10).fit_predict(np.vstack([dataset1[:2080,:],\n",
    "                                                                                    dataset1[3000:3080,:]]))\n",
    "kmeans_dataset2 = cluster.KMeans(n_clusters=4, max_iter=300, \n",
    "                                 init='k-means++',n_init=10).fit_predict(np.vstack([dataset1[-2080:,],\n",
    "                                                                                    dataset1[:80,]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_cluster(np.vstack([dataset1[:2080,],dataset1[3000:3080,]]), kmeans_dataset1, title1='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros\n",
    "\n",
    "Average complexity is O(k*n*T), where k,n and T are the number of clusters, samples and iterations, respectively. \n",
    "As such, it's considered one of the fastest clustering algorithms out there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variations of K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Variations on the k-means algorithm include [k-medoids](https://en.wikipedia.org/wiki/K-medoids) and [k-medians](https://en.wikipedia.org/wiki/K-medians_clustering), where centroids are updated to the [medoid](https://en.wikipedia.org/wiki/Medoid) and median of existng clusters, repsectively. Note that, under k-medoids, cluster centroids must correspond to the members of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* The [scikit clustering documentation](http://scikit-learn.org/stable/modules/clustering.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
